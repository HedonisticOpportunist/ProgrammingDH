{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Commonly used variables.\n",
        "book_chapter = \"/content/drive/MyDrive/Uni/DH/Sapir1921_chapter1.txt\" # Acquires the content of the e-book.\n",
        "stop_words_list = \"/content/drive/MyDrive/Uni/DH/stopwordlist.txt\" # Acquires the stop words."
      ],
      "metadata": {
        "id": "cOrOc9KQqMUL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to print out statements.\n",
        "# @ Credit: Previous assignment.\n",
        "def get_pretty_ouptut(explanation_str: str, result_str: str):\n",
        "  print(f'{explanation_str}: {result_str}')\n",
        "\n",
        "# Helper function to split a text into sentences.\n",
        "# @ Credit: Previous assignment.\n",
        "def split_text_into_sentences(text_content: str):\n",
        "  return text_content.split(\".\") # Split the text using a full stop."
      ],
      "metadata": {
        "id": "nN3z6znTyORO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Return the stop word list. #####\n",
        "# @Credit: Previous coding assignment.\n",
        "def create_stop_word_list_from_file(stop_word_list_file: str):\n",
        "  with open(stop_word_list_file, 'r', encoding=\"utf-16\") as file:\n",
        "      stop_words = [] # Create an empty list.\n",
        "      words = file.read() # Read the file.\n",
        "      stop_words = words.split() # Split the text into words/list.\n",
        "      return stop_words\n",
        "\n",
        "# Helper function for converting all words to lowercase.\n",
        "# @Credit: Previous coding assignment.\n",
        "def convert_words_to_lowercase(file_to_read: str):\n",
        "  with open(file_to_read, 'r') as file:\n",
        "    contents = file.read() # Read the file.\n",
        "    lower_case_words = contents.lower().split() # Turn the text to lowercase and then split it.\n",
        "    return lower_case_words\n",
        "\n",
        "# Convert all words to lowercase.\n",
        "# Remove stop words.\n",
        "# Return a cleaned list of words.\n",
        "# @Credit: Previous coding assignment.\n",
        "def process_text_for_frequency(text_content: str, stop_words_list):\n",
        "  cleaned_text_list = [] # Empty variable that is to be used later.\n",
        "  lower_case_words_list = convert_words_to_lowercase(text_content) # Convert all words to lowercase.\n",
        "  for word in lower_case_words_list: # Iterate through the lower case words list.\n",
        "    if word not in stop_words_list: # Condition that checks if the items in the list are not part of the stop words list.\n",
        "      cleaned_text_list.append(word) # Add item to the cleaned text list if not part of the stop words list.\n",
        "  return cleaned_text_list"
      ],
      "metadata": {
        "id": "6JBiaXCO90Tf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I0ZjfuO_iqSo"
      },
      "outputs": [],
      "source": [
        "#### Find and extract the longest sentence. ####\n",
        "# 1. Take the full text from a file as input.\n",
        "# 2. Find the sentence with the most words.\n",
        "# 3. Return that sentence.\n",
        "# @ Credit: Previous coding assignment and (see below):\n",
        "# https://systechgroup.in/blog-python-program-to-find-the-longest-word/.\n",
        "def find_longest_sentence(file_to_read: str):\n",
        "  with open(file_to_read, 'r') as file:\n",
        "      text_content = file.read() # Read the file.\n",
        "      sentences = split_text_into_sentences(text_content) # Split the text into sentences.\n",
        "      longest_sentence = max(sentences, key=len) # Get the longest sentences from the sentences list.\n",
        "      return longest_sentence.strip() # Strip the sentence of trailing white spaces before returning it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Find and extract the longest word. ####\n",
        "# 1. Take the full text from a file as input.\n",
        "# 2. Find the word with the most characters.\n",
        "# 3. Return that word.\n",
        "# @ Credit: Previous coding assignment, the function above and (see below):\n",
        "# https://stackoverflow.com/questions/72455305/finding-longest-word-in-a-txt-file\n",
        "def find_longest_word(file_to_read: str):\n",
        "  with open(file_to_read, 'r') as file:\n",
        "      text_content = file.read() # Read the file.\n",
        "      words = text_content.split() # Split the text into words.\n",
        "      return max(words, key=len).strip() # Get the maximum word in terms of length."
      ],
      "metadata": {
        "id": "mnQ4pjfpwIv4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Calculate the top frequencies in a given list. #####\n",
        "# 1. Take the cleaned word list.\n",
        "# 2 Count the frequency of each word.\n",
        "# 3 Return the Top Five words with their counts, including any tied words.\n",
        "# 4 Print the results in your program\n",
        "# @ Credit: https://labex.io/tutorials/python-how-to-use-set-to-count-element-frequencies-in-a-python-list-398089\n",
        "# as well as the previous coding assignment.\n",
        "def get_top_five_frequencies(cleaned_word_list):\n",
        "  all_frequencies = get_all_frequencies(cleaned_up_text)\n",
        "  # @Credit: https://www.geeksforgeeks.org/python/python-program-to-sort-the-list-according-to-the-column-using-lambda/\n",
        "  # and: https://www.geeksforgeeks.org/python/python-lambda-anonymous-functions-filter-map-reduce/\n",
        "  # for a better way to explain the line of code below. More specifically, a lambda function is a\n",
        "  # a neater way of checking for conditions, specifically using a function that has no name.\n",
        "  sorted_frequencies = sorted(all_frequencies.items(), key=lambda x: x[1], reverse=True) # x[1] sorts the second elements in the tuple, which is the count of frequencies each word has.\n",
        "  print(\"The top five frequencies in the text are: \")\n",
        "  return sorted_frequencies[:5] # Returns the top five frequencies, using array slicing: https://www.freecodecamp.org/news/python-slicing-how-to-slice-an-array/.\n",
        "\n",
        "# Helper function to get the word frequencies of the entire list.\n",
        "# @Credit: https://www.geeksforgeeks.org/python/counting-the-frequencies-in-a-list-using-dictionary-in-python/\n",
        "def get_all_frequencies(cleaned_word_list):\n",
        "  word_frequencies = {} # Creates an empty dictionary. https://www.w3schools.com/python/python_dictionaries.asp.\n",
        "  for word in cleaned_word_list:\n",
        "     word_frequencies[word] = word_frequencies.get(word, 0) + 1 # The following lines return the current count of word or zero if it doesnâ€™t exist. \"+1\" increases the count.\n",
        "  return word_frequencies"
      ],
      "metadata": {
        "id": "OFovB7PJtd4A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the functions above.\n",
        "longest_sentence = find_longest_sentence(book_chapter) # Find the longest sentence.\n",
        "get_pretty_ouptut('The longest sentence is', longest_sentence)\n",
        "\n",
        "longest_word = find_longest_word(book_chapter) # Find the longest word.\n",
        "get_pretty_ouptut('The longest word is', longest_word)\n",
        "\n",
        "stop_words = create_stop_word_list_from_file(stop_words_list) # Create the stop words list.\n",
        "# print(stop_words)\n",
        "\n",
        "cleaned_up_text = process_text_for_frequency(book_chapter, stop_words) # Process the text for frequency.\n",
        "# print(cleaned_up_text)\n",
        "\n",
        "top_five_frequencies = get_top_five_frequencies(cleaned_up_text) # Get the top five frequencies.\n",
        "print(top_five_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ-nqSx7mqYr",
        "outputId": "b254b7af-61ef-48f1-b699-2c104f22c3c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest sentence is: The word \"house\" is\n",
            "not a linguistic fact if by it is meant merely the acoustic effect\n",
            "produced on the ear by its constituent consonants and vowels, pronounced\n",
            "in a certain order; nor the motor processes and tactile feelings which\n",
            "make up the articulation of the word; nor the visual perception on the\n",
            "part of the hearer of this articulation; nor the visual perception of\n",
            "the word \"house\" on the written or printed page; nor the motor processes\n",
            "and tactile feelings which enter into the writing of the word; nor the\n",
            "memory of any or all of these experiences\n",
            "The longest word is: relation--physiologically\n",
            "The top five frequencies in the text are: \n",
            "[('speech', 63), ('language', 42), ('thought', 23), ('auditory', 20), ('motor', 20)]\n"
          ]
        }
      ]
    }
  ]
}